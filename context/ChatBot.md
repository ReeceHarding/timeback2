The Experimental Setup

Fifty-four Boston-area students wrote SAT-style essays under three conditions: ChatGPT only, Google only, or brain only.

Each person completed three timed sessions with the same condition, then an optional fourth session in the opposite condition.

A 32-channel Enobio headset recorded brain signals throughout, and every keystroke, prompt, and interview answer was archived for analysis.

Brain Connectivity Results

Alpha and beta networks were strongest when no external tool was allowed, moderate with Google, and weakest with ChatGPT.

Lower coupling during LLM use signals reduced internal attention and memory rehearsal, while high parieto-frontal flow in the brain-only group matches deep semantic processing.

Linguistic Patterns

Essays produced with ChatGPT clustered tightly in embedding space and reused the same named entities, showing high textual homogeneity.

Google essays sat in the middle, influenced by search rankings, whereas brain-only essays scattered widely, reflecting individual experience and vocabulary.

Memory and Ownership After writing, only 17 % of ChatGPT users could quote their own sentences, versus 89 % in the brain-only group. ChatGPT writers also reported the weakest sense of authorship, matching EEG evidence of reduced self-monitoring hubs.



Crossover Effects

When habitual ChatGPT users had to write unaided, their connectivity and quoting remained low, suggesting lingering cognitive debt.

In contrast, brain-only writers who switched to ChatGPT lit up wide networks and produced richer revisions, showing that tool use after deep practice boosts, rather than blunts, engagement.

Cognitive Load Implications

LLMs cut extraneous load by 32 % and extend productive time, yet they also trim germane load, so schema building suffers unless learners deliberately integrate ideas themselves.

Echo-Chamber Risk

Because a probabilistic model favors agreeable continuations, ChatGPT can tighten information loops more than a search page, shrinking exposure to contrasting facts and dulling critical thought.

Hooking sentence options

Here's the full transcription and interpretation of each figure you provided, followed by a summary explanation across all three graphs:

ðŸ”´ Figure 6: Participants Who Struggled to Quote Their Essays
Title: Figure 6. Percentage of participants within each group who struggled to quote anything from their essays in Session 1.
Graph Details:
Y-axis: Percentage of Participants (%)
X-axis groups:
LLM (red bar): ~80%
Search Engine (green bar): ~10â€“12%
Brain only (blue bar): ~10â€“12%
Interpretation:
This figure shows that participants who used LLMs were much more likely to struggle recalling or quoting anything from their essays compared to those who used search engines or relied solely on their brain. Nearly 80% of LLM users failed to quote from their essay, compared to only ~10% in other groups.

ðŸŸ©ðŸŸ¦ Figure 7: Participants Who Quoted Correctly
Title: Figure 7. Percentage of participants within each group who provided a correct quote from their essays in Session 1.
Graph Details:
Y-axis: Percentage of Participants who Succeeded (%)
X-axis groups:
LLM (red bar): ~5%
Search Engine (green bar): ~17%
Brain only (blue bar): ~11%
Statistical Annotations:
LLM:
T-stat: -9.22
p-value: <0.001
Search Engine:
T-stat: -1.66
p-value: <0.001
Brain only:
T-stat: -0.47
p-value: 0.641
Interpretation:
This figure reflects recall accuracy. The Search Engine group performed best, with around 17% quoting correctly. The LLM group had the worst performance (~5%)â€”significantly worse than both other groups. The p-value < 0.001 for LLM and Search Engine groups indicates the differences are statistically significant (especially between LLM and others), while the Brain-only vs. Search Engine comparison is not statistically significant (p = 0.641).

ðŸŸªðŸŸ§ðŸŸ¦ Figure 8: Perceived Ownership of Essays
Title: Figure 8. Relative reported percentage of perceived ownership of essay by the participants in comparison to the Brain-only group as a base in Session 1.
Graph Details:
Y-axis: Number of Participants
X-axis groups: LLM Group, Search Engine Group, Brain-only Group
Legend:
Purple: No Ownership
Red: Partial Ownership (50%)
Green: Partial Ownership (70%)
Orange: Partial Ownership (90%)
Blue: Full Ownership
Interpretation:
LLM Group: Fewer participants claimed full ownership (large blue section), and more claimed no ownership (purple) or partial ownership.
Search Engine Group: Moderate level of full ownership, with significant claims of partial ownership (especially 70% and 90%).
Brain-only Group: Almost entirely full ownership, with minimal claims of partial or no ownership.
This suggests that LLM users felt much less authorship over their essays, whereas those who wrote from memory or used search engines felt more ownership.

ðŸ§  Overall Summary: What These Graphs Say
1. Memory and Understanding Are Hindered by LLM Use
Participants who used LLMs struggled significantly to recall their writing, both in terms of:
Failure to recall any quotes (Figure 6)
Low success in quoting accurately (Figure 7)
2. Cognitive Engagement and Authorship Are Weakened
LLM users not only remembered less but also felt less ownership of what they wrote (Figure 8). This indicates lower cognitive engagement and identification with the writing process.
3. Search Engines Help, But Brain-Only Still Leads in Ownership
Search engine users outperformed LLM users in recall and felt higher ownership, but still didn't match the deep engagement and authorship reported by participants who composed essays without any external help.

Would you like a short writeup or slide summarizing these findings for presentation or internal use?


